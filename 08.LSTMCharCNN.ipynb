{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Character-Aware Neural Language Models\n",
    "We have seen RNN models can be used for language models. Now it's time to see how CNN can be used for language modeling\n",
    "\n",
    "### References\n",
    "- [Character-Aware Neural Language Models - Kim, 2016](https://arxiv.org/abs/1508.06615)\n",
    "- [yoonkim/lstm-char-cnn](https://github.com/yoonkim/lstm-char-cnn)\n",
    "- [mkroutikov/tf-lstm-char-cnn](https://github.com/mkroutikov/tf-lstm-char-cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Preprocessing codes are borrowed from [mkroutikov/tf-lstm-char-cnn](https://github.com/mkroutikov/tf-lstm-char-cnn). Preprocessed datasets are from [Jan Botha's Website](https://bothameister.github.io/)\n",
    "\n",
    "It's getting harder and harder to preprecess data in our model class. So we will preprocess before using `fit_to_corpus()` method as far as we can.\n",
    "\n",
    "You have to select among these datasets `en/es/cs/de/fr/ru/ptb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LSTMCharCNN\n",
    "import data.rnnlm_datasets.preprocess as preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "actual longest token length is: 21\n",
      "size of word vocabulary: 10000\n",
      "size of char vocabulary: 51\n",
      "number of tokens in train: 929589\n",
      "number of tokens in valid: 73760\n",
      "number of tokens in test: 82430\n"
     ]
    }
   ],
   "source": [
    "word_to_idx, char_to_idx, word_tensors, char_tensors, actual_max_word_length = \\\n",
    "    preprocess.build_dataset(\"ptb\", 30, eos='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word, valid_word, test_word, train_char, valid_char, test_char = \\\n",
    "    preprocess.train_test_dev_split(word_tensors, char_tensors)\n",
    "\n",
    "train_data = [train_word, valid_word, train_char, valid_char, word_to_idx, char_to_idx, actual_max_word_length]\n",
    "test_data = [test_word, test_char]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMCharCNN.LSTMCharCNN(hidden_size = 650,\n",
    "                                num_unroll_steps = 35,\n",
    "                                batch_size = 20,\n",
    "                                grad_clip = 5.,\n",
    "                                dropout_keep_prob = 0.5,\n",
    "                                learning_rate = 1.0,\n",
    "                                lstm_num_layer = 2,\n",
    "                                highway_num_layer = 2,\n",
    "                                char_embedding_size = 15,\n",
    "                                filter_windows = [1,2,3,4,5,6,7],\n",
    "                                num_filters = [50,100,150,200,200,200,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/young/.virtualenv/Tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "model.fit_to_corpus(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(50, save_dir=\"save/08_lstm_char_cnn/ptb\", log_dir=\"log/08_lstm_char_cnn/ptb\",\n",
    "                load_dir=\"save/08_lstm_char_cnn/ptb\", print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/08_lstm_char_cnn/ptb/epoch030_4.4012.model\n",
      "--------------------------------------------------------------------------------\n",
      "Restored model from checkpoint for testing. Size: 19365765\n",
      "--------------------------------------------------------------------------------\n",
      "test loss = 4.36729684, perplexity = 78.8302528\n",
      "test samples: 002340, time elapsed: 65.6426, time per one batch: 0.5610\n"
     ]
    }
   ],
   "source": [
    "model.test(test_data, load_dir=\"save/08_lstm_char_cnn/ptb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/08_lstm_char_cnn/ptb/epoch030_4.4012.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"the company 's new president + in the past two years mr. smith says he has n't seen the suit and the two sides have been working on a new york job\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample(30, load_dir=\"save/08_lstm_char_cnn/ptb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
