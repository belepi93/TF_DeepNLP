{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. DCNN - A Convolutional Neural Network for Modelling Sentences\n",
    "This is another usage of CNN for sentence classification. It's a little bit different from CNN by Kim (2014), but basic idea is similart to Kim. I failed to reproduce DCNN with TensorFlow. Anyway, if you're interested, you could take a look at my code.\n",
    "\n",
    "### References\n",
    "- [A Convolutional Neural Network for Modelling Snentece - Kalchbrenner et al. 2014](https://arxiv.org/abs/1404.2188)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Preprocessing codes and processed data are borrowed from [harvardnlp/sent-conv-torch](https://github.com/harvardnlp/sent-conv-torch).\n",
    "\n",
    "It's getting harder and harder to preprecess data in our model class. So we will preprocess before using `fit_to_corpus()` method as far as we can.\n",
    "\n",
    "You have to select among these datasets `MR/SST1/SST2/Subj/TREC/CR/MPQA`.\n",
    "\n",
    "Note that we are using phrases in SST1 for training though Kalchbrenner didn't use phrases in his paper. So there will be some differences in results from paper. But it'll make it easy for us to compare the results from DCNN with ones from CNN (Kim, 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.sentiment_datasets.preprocess as preprocess\n",
    "from models import DCNN\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use pretrained word2vec here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data..\n",
      "Vocab size: 16189\n",
      "train size: (6920, 53)\n"
     ]
    }
   ],
   "source": [
    "train, train_label, test, test_label, dev, dev_label, word_to_idx = preprocess.build_dataset(\"SST2\", use_w2v=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, dev, train_label, test_label, dev_label = \\\n",
    "    preprocess.train_test_dev_split(train, test, dev, train_label, test_label, dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [train, train_label, dev, dev_label, word_to_idx]\n",
    "test_data = [test, test_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training!\n",
    "I tried to reproduced the result from the paper but failed due to the lack of information of specific parameters used in producing the result in paper. If you're able to read theano code, look [FredericGodin/DynamicCNN\n",
    "](https://github.com/FredericGodin/DynamicCNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCNN.DCNN(batch_size = 20,\n",
    "                  word_embedding_size = 48,\n",
    "                  learning_rate = 0.001,\n",
    "                  filter_windows = [7,5],\n",
    "                  k_top = 4,\n",
    "                  feature_maps = [6,14],\n",
    "                  dropout_keep_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/young/.virtualenv/NLP/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "model.fit_to_corpus(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Created and Initialized fresh model. Size: 778916\n",
      "--------------------------------------------------------------------------------\n",
      "000300: 1 [00300/00346], train_loss = 0.49299794, accuracy = 0.85000002, secs/batch = 0.0220\n",
      "Epoch training time: 8.033319234848022\n",
      "\n",
      "Finished Epoch 1\n",
      "train_loss = 0.60728546, train_accruacy = 0.64595376\n",
      "valid_loss = 0.45201360, valid_accuracy = 0.79302325\n",
      "\n",
      "000646: 2 [00300/00346], train_loss = 0.42926663, accuracy = 0.80000001, secs/batch = 0.0215\n",
      "Epoch training time: 6.976386547088623\n",
      "\n",
      "Finished Epoch 2\n",
      "train_loss = 0.28037934, train_accruacy = 0.89205202\n",
      "valid_loss = 0.45281738, valid_accuracy = 0.80813954\n",
      "\n",
      "000992: 3 [00300/00346], train_loss = 0.15770006, accuracy = 0.94999999, secs/batch = 0.0222\n",
      "Epoch training time: 6.928498983383179\n",
      "\n",
      "Finished Epoch 3\n",
      "train_loss = 0.08518868, train_accruacy = 0.98049132\n",
      "valid_loss = 0.66393911, valid_accuracy = 0.79418605\n",
      "\n",
      "decaying learning rate by half..\n",
      "learning rate was: 0.001\n",
      "new learning rate is: 0.0005000000237487257\n",
      "001338: 4 [00300/00346], train_loss = 0.05067350, accuracy = 1.00000000, secs/batch = 0.0225\n",
      "Epoch training time: 6.838239431381226\n",
      "\n",
      "Finished Epoch 4\n",
      "train_loss = 0.03385700, train_accruacy = 0.99653179\n",
      "valid_loss = 0.75887992, valid_accuracy = 0.79767442\n",
      "\n",
      "decaying learning rate by half..\n",
      "learning rate was: 0.0005\n",
      "new learning rate is: 0.0002500000118743628\n"
     ]
    }
   ],
   "source": [
    "model.train(4, save_dir=\"save/09_dcnn/sst2\", log_dir=\"log/09_dcnn/sst2\", print_every=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/09_dcnn/sst2/epoch004_0.7589.model\n",
      "--------------------------------------------------------------------------------\n",
      "Restored model from checkpoint for testing. Size: 778916\n",
      "--------------------------------------------------------------------------------\n",
      "test loss = 0.67550432, test accuracy = 0.81208791\n",
      "test samples: 001820, time elapsed: 1.2287, time per one batch: 0.0135\n"
     ]
    }
   ],
   "source": [
    "model.test(test_data, load_dir=\"save/09_dcnn/sst2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
